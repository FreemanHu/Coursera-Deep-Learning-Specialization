# Deep Learning Specialization
## Andrew Ng, 吴恩达
## 传送门: https://www.coursera.org/specializations/deep-learning
1. Neural Networks and Deep Learning  
- 深度学习介绍:   
    - CNN, RNN   
    - structured data, unstructured data;   
    - Idea, Code, Experiment  
- 深度学习基础  
    - 流程     
        - 前向传播计算代价函数  
        - 反向传播计算偏导数  
        - 优化  
    - Python广播机制  
- 浅层神经网络(1个隐藏层)      
    - 线性函数  
    - 激活函数    
    - 权重系数随机初始化(应尽量小)    
- 深度神经网络(多个隐藏层)  
    - 系数矩阵的维度  
    - 超参数:  
        - learning_rate  
        - #iteration  
        - #hidden layer L  
        - #hidden units  
        - choice of activation function            
2. Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization  
- 深度学习实践   
    - 训练集/开发集/测试集  
        - 中量数据: 70/30 or 60/20/20  
        - 大量数据: 98/1/1  
    - 偏差和方差
        - 高偏差: 更大的神经网络，训练更长的时间
        - 高方差: 更多的数据，正则化
    - 正则化  
        - L2正则化  
        - dropout
        - 数据增补  
        - 早停止  
    - 建议
        - 输入归一化  
        - 挑选合适的权重进行初始化(He)  
        - 梯度检测  
- 优化算法  
    - 小批量梯度下降  
        - 1 < size < m  
        - mini-batch size = 64, 128, 256, 512  
    - 指数加权滑动平均  
        - 1/(1-beta)时间内的平均值
        - 偏差修正  
    - Momentum  
        - 对dw, db进行滑动加权平均
        - beta=0.9效果较好  
        - 一般不进行偏差修正  
    - RMSprop  
        - 对dw^2, db^2进行滑动加权平均  
        - epsilon=10^-8效果较好
        - 一般不进行偏差修正  
    - Adam  
        - 结合了Momentum + RMSprop
        - 偏差修正 
        - 效果非常好  
    - 学习率衰减  
        - 在优化过程中不断改变学习率  
        - 较晚考虑  
- 超参数搜索, 批量归一化和编程框架  
    - 超参数搜索  
        - 随机搜索  
        - 线性平均随机搜索  
        - 指数平均随机搜索  
    - 批量归一化  
        - 训练集: 代入公式   
        - 测试集: 对训练集的参数进行滑动加权平均  
    - 多类别分类  
        - softmax  
        - 交叉熵  
    - 深度学习框架  
        - Tensorflow
3. Structuring Machine Learning Projects  
- 机器学习策略1  
    - 正交化超参数  
    - 设置单一的量化评估指标  
        - (准确率，召回率) -> F1-score
        - 优化指标(1个)和满足指标(N-1个)
    - 开发集/测试集
        - 必须来自同一分布
        - 必须随机选取
    - 修改评估指标
    - bias/varience权衡
        - bayes error
        - avoidable bias
        - varience  
4. Convolutional Neural Networks  
- 神经网络基础
    - 边缘检测  
    - 填充，步长  
    - 卷积层，池化层，全连接层
        - 为什么进行卷积？  
        - 如何进行卷积？  
    - 作业1: Convolutional model - Step by Step  
        - 用Python搭建卷积神经网络  
        - vert_start = stride * h  
        - vert_end = vert_start + f  
        - horiz_start = stride * w  
        - horiz_end = horiz_start + f  
    - 作业2: Convolutional Neural Networks: Application  
        - 用tensorflow实现卷积神经网络，对人手表示的不同数字进行识别(分类问题)  
        - tf.contrib.layers.flatten(P)  
        - tf.contrib.layers.fully_connected(F, num_outputs)  
        - 经过训练，在训练集上的准确率达到94%，在测试集上的准确率达到78%，模型过拟合了  
- 神经网络经典模型
    - LeNet-5  
        - 2*Conv + 3*Fc  
    - AlexNet  
        - 5*Conv + 3*Fc  
    - VGG-16  
        - 13*Conv + 3*Fc
    - ResNet  
        - 残差块的组成  
        - 为什么使用残差神经网路？  
        - 残差神经网络的优点
    - Inception  
        - 1*1的卷积核有什么作用？  
        - 实现: 将多个尺寸的卷积核一起使用  
        - 瓶颈层  
        - 将多个inception组合成Inception Network  
    - 使用建议  
        - 迁移学习: 根据你的数据量选择需要训练的层数  
        - 数据增强: 当图像数据不足的时候，进行数据增强  
        - 模型融合: 训练多个神经网络并对输出取平均值  
        - 多种裁剪: 将网络运行在多个版本的测试集上，对输出取平均值  
    - 作业1: Keras tutorial: Happy House    
        - 运用keras搭建一个分类系统，对于happy的人输出1，unhappy的人输出0  
        - 最终系统在给出的测试集中准确率达到98%，表现很好，但我自己上传了几张照片发现不能很好的判断，可能是因为图片的大小不是64*64导致信息丢失  
    - 作业2: Residual Networks  
        - 运用keras搭建了一个50层的残差神经网络，对第一周的数字手势进行训练  
        - 因为训练时间太长了，我直接加载了达叔训练好的模型，在测试集上的正确率达到86%，有很大提升  
        - 但是我自己的上传的照片它还是识别错了，哈哈，可能是因为我吧手后面的作业本拍进去了，有太多的噪声  
- 目标检测  
    - 滑动窗口检测  
        - 先训练一个能识别汽车图片的CNN，输入是经过裁剪的汽车图片（只包含汽车），输出是类别  
        - 选用一定大小的f和stride分割测试集图片，将分割出的图片输入上一步的CNN中得到预测结果  
        - 可以用卷积神经网络减少计算量  
        - 但是，还有什么缺点？  
        - 无法输出精确的边界框，目标物体可能不会出现在任何一个滑动窗口内  
    - YOLO  
        - 交并比(IoU),非最大值抑制(Non-max suppression),锚框(Anchor box)  
        - 为什么要用anchor box以及它的缺陷  
        - 一般将图片划分为19*19的网格(grid cell)，一般使用使用2个锚框(Anchor box)  
        - 对每个测试图片进行预测，每个格子都会输出2个预测框，丢弃低得分的预测框，并对剩余的预测框进行非最大值抑制
            - (1) 选择最高得分的box  
            - (2) 计算它与所有其他box的IoU，并移除所有IoU>iou_threshold的box  
            - (3) 重复(1)直到没有剩余的box  
    - 候选区域  
        - R-CNN, Fast R-CNN, Faster R-CNN   
    - 作业:  Autonomous driving-Car detection  
        - 主要实现yolo算法预测目标的部分，模型达叔帮我们训练好了
        - 输入图片 (608, 608, 3)  
        - 经过一个CNN训练, 得到一个 (19,19,5,85)的输出  
            - 19*19的网格，5个anchor box  
            - 85 = 5 + 80，5代表$(p_c, b_x, b_y, b_h, b_w)$有5项，80代表检测80个类别  
        - 筛选锚框:  
            - Score-thresholding: 丢弃得分低于score_threshold的box  
            - Non-max suppression: 根据非最大值抑制算法进一步筛选box  
        - 得到输出  
- 前沿应用: 人脸识别及图像风格迁移  
    - 人脸验证  
        - 案例: 人脸解锁手机  
        - 1:1   
        - 网络训练方法:  
            - 用logistic regression作为输出  
            - 损失函数用j交叉熵(这一点达叔在视频中并没有提及，只是我的推测)  
    - 人脸识别  
        - 案例: 公司人脸打卡  
        - 1:n 
        - 网络训练方法:  
            - 目标函数: triplet loss(A, P, N)  
            - (A, P)应该选择同一个人，(A, N)应该选择不同的人  
    - 作业1: Face Recognition for the Happy House  
        - 主要实现人脸识别和人脸验证算法的预测部分，模型直接加载了达叔给的最优参数  
        - 人脸验证(1:1): 
            - 根据输入的(名字, 图片)计算编码  
            - 跟数据库中该名字对应的图片的编码，与上一步的编码比对计算L2范数  
            - 如果L2范数小于阈值(此处选择0.7)，表明是同一个人  
        - 人脸识别(1:n):
            - 只输入图片，根据该图片计算编码  
            - 将该编码与数据库中所有的编码进行比较，筛选出L2范数最小的那个  
            - 输出结果  
    - 神经风格迁移  
        - 根据图片C的内容(content)和图片S的风格(style)生成图片G  
        - 这是一个无监督学习任务  
        - 损失函数: alpha*J(C, G) + beta*J(S, G)  
        - J(C, G): 选择预先训练好的卷积神经网络，计算第l层的激活函数，并求出两张图片对应的输出的距离  
        - J(S, G): 
            - 也是使用第l层的激活函数值  
            - 计算不同通道间的相关系数(Style Matrix)  
            - 计算风格矩阵的距离  
            - 实践中，发现综合多层的值求平均后效果更好  
    - 作业2:  Deep Learning & Art: Neural Style Transfer  
        - 预先加载一个训练好的图像分类模型(VGG)  
        - 通过C计算content cost  
        - 通过S计算style cost  
        - total cost = alpha*content_cost + beta*style_cost(一般取alpha=10，beta=40)  
        - 参数: G的像素值是可训练的参数  
        - 超参数: alpha, bate, 迭代次数，style layers各层的权重  
    - 1D卷积: 应用于心电图  
    - 3D卷积: 应用于CAT扫描，视频处理  
5. Sequence Models
- 循环神经网络
    - RNN的应用: 语音识别，音乐生成，情感分析，DNA序列分析，机器翻译，视频序列检测，序列识别(检测人名)  
    - 如何表示输入数据？词汇表 + one-hot编码  
    - 基本RNN模型: 一层RNN，输入是序列，如(batch_size, time_steps, features)，输出也是序列，如(batch_size, time_steps, n_a)。在RNN内部会对t个时刻进行循环运算，即a<t-1>会输入到第t个时刻与x<t>一起运算  
    - 不同种类的RNN模型  
        - one-to-one  
        - one-to-many
        - many-to-one
        - many-to-many(Tx = Ty)
        - many-to-many(Tx != Ty)
    - 应用: 文本生成(单词级语言模型和字符级语言模型)  
        - 训练: 令x<i> = y<t-1>，计算y_hat<t>=P( y<t> | y<1>, y<2>, ... , y<t-1> )，loss<t>=y<t>与y_hat<t>的交叉熵，loss=sum(loss<i>)，优化器优化总loss使其最小
        - 预测(生成文本): x<1>=0，计算y_hat<0>，对其进行采样生成x<1>。每一步的x<t>都是根据y_hat<t-1>的概率分布对词汇表进行采样，然后再计算新的y_hat<t>
        - 单词级语言模型计算量小，模型易训练，但是可能会出现未知词
        - 字符级语言模型计算量大，模型难训练，但不会出现未知词
    - 普通RNN具有的问题
        - 梯度爆炸: 某一时刻的梯度太大以致更新后的梯度溢出，比较好解决，可以通过梯度裁剪(gradient clipping)
        - 梯度消失: 因为时间序列太长，后面时刻的梯度很难传播到前面时刻，较好的解决方法: GRU, LSTM
    - GRU
        - 在普通RNN的基础上增加了记忆单元c<t>，并增加了更新门和相关性门对c<t>进行更新，而且a<t>=c<t>
        - 更新门和相关性门都是根据c<t-1>与x<t>计算得到的，激活函数都使用sigmoid，值都在0-1之间
        - 更新记忆单元的公式为: c<t> = Fu * c_hat<t> + (1-Fu) * c<t-1>
        - 更新激活单元的公式为: a<t> = c<t>
        - 由公式可知，当Fu=0时，c<t>=c<t-1>，不进行更新；当Fu=1时，c<t>=c_hat<t>，用当前时刻计算的值更新。这就大大缓解了梯度消失的问题(可类比残差神经网络)
    - LSTM
        - 在普通RNN的基础上增加了记忆单元c<t>，并增加了遗忘门，更新门，输出门对c<t>和a<t>进行更新，此处a<t>一般不等于c<t>
        - 更新门，遗忘门，输出门都是根据c<t-1>与x<t>计算得到的，激活函数都使用sigmoid，值都在0-1之间
        - 更新记忆单元的公式为: c<t> = Fu * c_hat<t> + Ff * c<t-1>
        - 更新激活单元的公式为: a<t> = Fo * tanh(c<t>)
    - BRNN
        - 每一时刻t有两个RNN单元在工作，这里的RNN单元可以是基本RNN，GRU或者LSTM
        - 第一个RNN考虑1, 2, 3, ..., t-1时刻的输出，第二个RNN考虑t+1, t+2, ..., n时刻的输出，相当于t时刻的预测是综合考虑了前后序列的状态
        - 缺点是实时性较差，需要得到整个序列才能开始运算
    - 深度RNN模型：将多层RNN进行堆叠以获得更强大的学习效果
    - 作业1：Building your Recurrent Neural Network - Step by Step
        - 自己动手搭建基本RNN模型和LSTM模型
        - RNN：前向传播还是很容易实现的，反向传播的时候注意梯度除了来自后一个时刻的梯度外，还要加上当前时刻的loss对需要更新的参数的梯度
        - LSTM：这个前向传播也容易实现的，反向传播就坑了，达叔给的公式错了，纠正公式错误就花了不少时间，然后在对整个序列求梯度的时候原来的代码写错了，我自己参照助教的解释更新了代码
    - 作业2：Character level language model - Dinosaurus land
        - 对恐龙名字进行预测，其实就是一个字符级的语言模型
        - 需要自己实现梯度裁剪，预测采样
    - 作业3：Improvise a Jazz Solo with an LSTM Network
        - 这是一个one-to-many的模型，在训练好的模型上生成了一段音乐，试听感觉不错，需要注意的是，这是一个多输入多输出的模型，运用keras进行搭建
        - 由于这个模型存在30个损失函数，而优化器在优化的时候只能对一个值进行优化，所以是对30个损失函数的和进行优化
        - 其他的就跟作业2差不多了，最后生成的音乐需要经过处理函数才能播放，不过达叔也帮我们写好了，只要调用下即可～
    
